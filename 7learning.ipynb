{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Query for downloading the data from Google Cloud BIGQUERY"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SELECT\n",
    "  *,\n",
    "  FORMAT_TIMESTAMP('%Y-%m-%d', TIMESTAMP(CONCAT(CAST(year AS STRING), '-', CAST(month AS STRING), '-', CAST(day AS STRING)))) AS formatted_date\n",
    "FROM\n",
    "  `bigquery-public-data.samples.gsod`\n",
    "WHERE\n",
    "  year BETWEEN 2005 AND 2009\n",
    "  AND station_number BETWEEN 725300 AND 726300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The dataset was downloaded as csv and later uploaded in Visual Studio where futher processing was performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_572666/1797354241.py:2: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv('/root/code/thesis/codeFolder/LatestDataInUse/csv/7learnings.csv')\n"
     ]
    }
   ],
   "source": [
    "#importing dataset by reading csv file (The data was downloaded from Google Cloud using BIGQUERY)\n",
    "df=pd.read_csv('/root/code/thesis/codeFolder/LatestDataInUse/csv/7learnings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_number</th>\n",
       "      <th>wban_number</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>num_mean_temp_samples</th>\n",
       "      <th>mean_dew_point</th>\n",
       "      <th>num_mean_dew_point_samples</th>\n",
       "      <th>mean_sealevel_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>min_temperature_explicit</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>hail</th>\n",
       "      <th>thunder</th>\n",
       "      <th>tornado</th>\n",
       "      <th>formatted_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>725940</td>\n",
       "      <td>99999</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>51.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>45.299999</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1013.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2005-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725940</td>\n",
       "      <td>99999</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2005-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>725940</td>\n",
       "      <td>99999</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>45.700001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1021.799988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2005-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>725869</td>\n",
       "      <td>99999</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>30.200001</td>\n",
       "      <td>5</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2005-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>725827</td>\n",
       "      <td>99999</td>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>28.799999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1015.599976</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2005-10-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_number  wban_number  year  month  day  mean_temp  \\\n",
       "0          725940        99999  2005      1   25  51.299999   \n",
       "1          725940        99999  2005      3    7  51.500000   \n",
       "2          725940        99999  2005      5   11  51.000000   \n",
       "3          725869        99999  2005      1   27  30.200001   \n",
       "4          725827        99999  2005     10   23  55.000000   \n",
       "\n",
       "   num_mean_temp_samples  mean_dew_point  num_mean_dew_point_samples  \\\n",
       "0                      4       45.299999                         4.0   \n",
       "1                      4       48.000000                         4.0   \n",
       "2                      4       45.700001                         4.0   \n",
       "3                      5       26.600000                         5.0   \n",
       "4                      5       28.799999                         5.0   \n",
       "\n",
       "   mean_sealevel_pressure  ...  min_temperature_explicit  total_precipitation  \\\n",
       "0             1013.500000  ...                       NaN                 0.00   \n",
       "1             1025.000000  ...                       NaN                 0.00   \n",
       "2             1021.799988  ...                       NaN                 0.01   \n",
       "3                     NaN  ...                       NaN                 0.00   \n",
       "4             1015.599976  ...                       NaN                 0.00   \n",
       "\n",
       "   snow_depth    fog   rain   snow   hail  thunder  tornado  formatted_date  \n",
       "0         NaN  False  False  False  False    False    False      2005-01-25  \n",
       "1         NaN  False  False  False  False    False    False      2005-03-07  \n",
       "2         NaN  False  False  False  False    False    False      2005-05-11  \n",
       "3         NaN  False  False  False  False    False    False      2005-01-27  \n",
       "4         NaN  False  False  False  False    False    False      2005-10-23  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering stations 725300 to 725330 that have information from 2005 till 2009.\n",
    "df = df[(df['station_number'] >= 725300) & (df['station_number'] <= 725330)]\n",
    "\n",
    "# Specify the columns to drop \n",
    "# Some of these column like were irrelevant, some coulumns had missing values\n",
    "columns_to_drop = ['min_temperature', 'min_temperature_explicit','mean_station_pressure','mean_sealevel_pressure', 'num_mean_station_pressure_samples','year','month','day','snow_depth', 'num_mean_sealevel_pressure_samples', 'wban_number', 'num_mean_temp_samples','num_mean_dew_point_samples', 'num_mean_visibility_samples' ,'max_sustained_wind_speed','max_gust_wind_speed','max_temperature_explicit', 'num_mean_wind_speed_samples','tornado','max_temperature']\n",
    "\n",
    "# Drop the specified columns\n",
    "df_dropped = df.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_wind_speed', 'total_precipitation']\n"
     ]
    }
   ],
   "source": [
    "# Checking columns with NAN values\n",
    "columns_with_nan = df_dropped.columns[df_dropped.isna().any()].tolist()\n",
    "\n",
    "print(columns_with_nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strategies for dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Strategy 1: Filling the missing values with mean values\n",
    "#data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "### Strategy 2: Interpolating the missing values\n",
    "#df_dropped['mean_wind_speed'] = df_dropped['mean_wind_speed'].interpolate()\n",
    "#df_dropped['total_precipitation'] = df_dropped['total_precipitation'].interpolate()\n",
    "#df_dropped['mean_sealevel_pressure'] = df_dropped['mean_sealevel_pressure'].interpolate()\n",
    "\n",
    "### Strategy 3: Droping the missing rows\n",
    "df_dropped=df_dropped.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Droping the rows with missing values reduces data size but other strategies are more likely to compromise data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Find columns with NaN values\n",
    "columns_with_nan = df_dropped.columns[df_dropped.isna().any()].tolist()\n",
    "\n",
    "print(columns_with_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the dataframe with respect to data and resting the dataframe index\n",
    "final_df = df_dropped.sort_values(by='formatted_date') \n",
    "final_df = final_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_number</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>mean_dew_point</th>\n",
       "      <th>mean_visibility</th>\n",
       "      <th>mean_wind_speed</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>hail</th>\n",
       "      <th>thunder</th>\n",
       "      <th>formatted_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>725314</td>\n",
       "      <td>60.799999</td>\n",
       "      <td>57.599998</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2005-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725300</td>\n",
       "      <td>32.299999</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2005-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>725330</td>\n",
       "      <td>24.799999</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2005-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>725305</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2005-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>725316</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2005-01-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_number  mean_temp  mean_dew_point  mean_visibility  \\\n",
       "0          725314  60.799999       57.599998              8.9   \n",
       "1          725300  32.299999       29.400000              7.7   \n",
       "2          725330  24.799999       20.400000              9.7   \n",
       "3          725305  16.700001       13.100000              8.4   \n",
       "4          725316  28.600000       25.500000              7.3   \n",
       "\n",
       "   mean_wind_speed  total_precipitation    fog   rain   snow   hail  thunder  \\\n",
       "0              4.8                 0.40  False  False  False  False    False   \n",
       "1              9.3                 0.34   True   True   True   True     True   \n",
       "2              7.7                 0.03  False  False  False  False    False   \n",
       "3              6.9                 0.01  False  False  False  False    False   \n",
       "4              5.4                 0.10   True   True   True   True     True   \n",
       "\n",
       "  formatted_date  \n",
       "0     2005-01-02  \n",
       "1     2005-01-04  \n",
       "2     2005-01-07  \n",
       "3     2005-01-07  \n",
       "4     2005-01-08  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station_number', 'mean_temp', 'mean_dew_point', 'mean_visibility',\n",
       "       'mean_wind_speed', 'total_precipitation', 'fog', 'rain', 'snow', 'hail',\n",
       "       'thunder', 'formatted_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the categorical values to numerical values\n",
    "final_df['fog'] = final_df['fog'].astype(int)\n",
    "final_df['rain'] = final_df['rain'].astype(int)\n",
    "final_df['hail'] = final_df['hail'].astype(int)\n",
    "final_df['thunder'] = final_df['thunder'].astype(int)\n",
    "final_df['snow'] = final_df['snow'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_number</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>mean_dew_point</th>\n",
       "      <th>mean_visibility</th>\n",
       "      <th>mean_wind_speed</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>hail</th>\n",
       "      <th>thunder</th>\n",
       "      <th>formatted_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>725314</td>\n",
       "      <td>60.799999</td>\n",
       "      <td>57.599998</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725300</td>\n",
       "      <td>32.299999</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>725330</td>\n",
       "      <td>24.799999</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>725305</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>725316</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2005-01-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_number  mean_temp  mean_dew_point  mean_visibility  \\\n",
       "0          725314  60.799999       57.599998              8.9   \n",
       "1          725300  32.299999       29.400000              7.7   \n",
       "2          725330  24.799999       20.400000              9.7   \n",
       "3          725305  16.700001       13.100000              8.4   \n",
       "4          725316  28.600000       25.500000              7.3   \n",
       "\n",
       "   mean_wind_speed  total_precipitation  fog  rain  snow  hail  thunder  \\\n",
       "0              4.8                 0.40    0     0     0     0        0   \n",
       "1              9.3                 0.34    1     1     1     1        1   \n",
       "2              7.7                 0.03    0     0     0     0        0   \n",
       "3              6.9                 0.01    0     0     0     0        0   \n",
       "4              5.4                 0.10    1     1     1     1        1   \n",
       "\n",
       "  formatted_date  \n",
       "0     2005-01-02  \n",
       "1     2005-01-04  \n",
       "2     2005-01-07  \n",
       "3     2005-01-07  \n",
       "4     2005-01-08  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1524, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([725300, 725305, 725314, 725315, 725316, 725317, 725320, 725326,\n",
       "       725327, 725330])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(final_df['station_number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset has huge class imbalance with 1350 values representing class 0 \"no snow\" and only 174 values prepresenting class 1 \"snow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1350\n",
       "1     174\n",
       "Name: snow, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['snow'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data into train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create features and labels\n",
    "features = ['station_number', 'mean_temp', 'mean_dew_point', 'mean_visibility',\n",
    "            'mean_wind_speed', 'total_precipitation', 'fog', 'rain', 'hail',\n",
    "            'thunder']\n",
    "X = final_df[features]\n",
    "\n",
    "y = final_df['snow'].shift(-1).fillna(0).astype(int)  # Forecasting snow on the next day\n",
    "\n",
    "# Splitting the data into train test split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Converting the labels to numpy arrays\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features to ensure equal weitage of each feature\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom dataset class\n",
    "class ClimateDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "class SnowForecastNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SnowForecastNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.5706, Train Accuracy: 78.67%, Test Loss: 0.4306, Test Accuracy: 88.52%\n",
      "Epoch 2/100, Train Loss: 0.3737, Train Accuracy: 88.60%, Test Loss: 0.3491, Test Accuracy: 88.52%\n",
      "Epoch 3/100, Train Loss: 0.3481, Train Accuracy: 88.60%, Test Loss: 0.3443, Test Accuracy: 88.52%\n",
      "Epoch 4/100, Train Loss: 0.3425, Train Accuracy: 88.60%, Test Loss: 0.3420, Test Accuracy: 88.52%\n",
      "Epoch 5/100, Train Loss: 0.3414, Train Accuracy: 88.60%, Test Loss: 0.3420, Test Accuracy: 88.52%\n",
      "Epoch 6/100, Train Loss: 0.3392, Train Accuracy: 88.60%, Test Loss: 0.3416, Test Accuracy: 88.52%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Train Loss: 0.3365, Train Accuracy: 88.60%, Test Loss: 0.3411, Test Accuracy: 88.52%\n",
      "Epoch 8/100, Train Loss: 0.3563, Train Accuracy: 88.60%, Test Loss: 0.3389, Test Accuracy: 88.52%\n",
      "Epoch 9/100, Train Loss: 0.3360, Train Accuracy: 88.60%, Test Loss: 0.3401, Test Accuracy: 88.52%\n",
      "Epoch 10/100, Train Loss: 0.3334, Train Accuracy: 88.60%, Test Loss: 0.3397, Test Accuracy: 88.52%\n",
      "Epoch 11/100, Train Loss: 0.3323, Train Accuracy: 88.60%, Test Loss: 0.3380, Test Accuracy: 88.52%\n",
      "Epoch 12/100, Train Loss: 0.3327, Train Accuracy: 88.60%, Test Loss: 0.3394, Test Accuracy: 88.52%\n",
      "Epoch 13/100, Train Loss: 0.3319, Train Accuracy: 88.60%, Test Loss: 0.3371, Test Accuracy: 88.52%\n",
      "Epoch 14/100, Train Loss: 0.3511, Train Accuracy: 88.60%, Test Loss: 0.3362, Test Accuracy: 88.52%\n",
      "Epoch 15/100, Train Loss: 0.3513, Train Accuracy: 88.60%, Test Loss: 0.3368, Test Accuracy: 88.52%\n",
      "Epoch 16/100, Train Loss: 0.3467, Train Accuracy: 88.60%, Test Loss: 0.3364, Test Accuracy: 88.52%\n",
      "Epoch 17/100, Train Loss: 0.3426, Train Accuracy: 88.60%, Test Loss: 0.3361, Test Accuracy: 88.52%\n",
      "Epoch 18/100, Train Loss: 0.3291, Train Accuracy: 88.60%, Test Loss: 0.3324, Test Accuracy: 88.52%\n",
      "Epoch 19/100, Train Loss: 0.3267, Train Accuracy: 88.60%, Test Loss: 0.3348, Test Accuracy: 88.52%\n",
      "Epoch 20/100, Train Loss: 0.3277, Train Accuracy: 88.60%, Test Loss: 0.3333, Test Accuracy: 88.52%\n",
      "Epoch 21/100, Train Loss: 0.3249, Train Accuracy: 88.60%, Test Loss: 0.3345, Test Accuracy: 88.52%\n",
      "Epoch 22/100, Train Loss: 0.3435, Train Accuracy: 88.60%, Test Loss: 0.3352, Test Accuracy: 88.52%\n",
      "Epoch 23/100, Train Loss: 0.3259, Train Accuracy: 88.60%, Test Loss: 0.3338, Test Accuracy: 88.52%\n",
      "Epoch 24/100, Train Loss: 0.3476, Train Accuracy: 88.60%, Test Loss: 0.3354, Test Accuracy: 88.52%\n",
      "Epoch 25/100, Train Loss: 0.3267, Train Accuracy: 88.60%, Test Loss: 0.3342, Test Accuracy: 88.52%\n",
      "Epoch 26/100, Train Loss: 0.3222, Train Accuracy: 88.60%, Test Loss: 0.3338, Test Accuracy: 88.52%\n",
      "Epoch 27/100, Train Loss: 0.3383, Train Accuracy: 88.60%, Test Loss: 0.3336, Test Accuracy: 88.52%\n",
      "Epoch 28/100, Train Loss: 0.3225, Train Accuracy: 88.60%, Test Loss: 0.3329, Test Accuracy: 88.52%\n",
      "Epoch 29/100, Train Loss: 0.3213, Train Accuracy: 88.60%, Test Loss: 0.3350, Test Accuracy: 88.20%\n",
      "Epoch 30/100, Train Loss: 0.3402, Train Accuracy: 88.60%, Test Loss: 0.3332, Test Accuracy: 88.52%\n",
      "Epoch 31/100, Train Loss: 0.3197, Train Accuracy: 88.60%, Test Loss: 0.3334, Test Accuracy: 88.52%\n",
      "Epoch 32/100, Train Loss: 0.3182, Train Accuracy: 88.60%, Test Loss: 0.3346, Test Accuracy: 88.52%\n",
      "Epoch 33/100, Train Loss: 0.3368, Train Accuracy: 88.68%, Test Loss: 0.3330, Test Accuracy: 88.52%\n",
      "Epoch 34/100, Train Loss: 0.3175, Train Accuracy: 88.76%, Test Loss: 0.3348, Test Accuracy: 88.52%\n",
      "Epoch 35/100, Train Loss: 0.3258, Train Accuracy: 88.68%, Test Loss: 0.3351, Test Accuracy: 88.20%\n",
      "Epoch 36/100, Train Loss: 0.3320, Train Accuracy: 88.68%, Test Loss: 0.3344, Test Accuracy: 88.52%\n",
      "Epoch 37/100, Train Loss: 0.3150, Train Accuracy: 88.76%, Test Loss: 0.3322, Test Accuracy: 88.20%\n",
      "Epoch 38/100, Train Loss: 0.3174, Train Accuracy: 88.68%, Test Loss: 0.3343, Test Accuracy: 88.52%\n",
      "Epoch 39/100, Train Loss: 0.3131, Train Accuracy: 88.68%, Test Loss: 0.3356, Test Accuracy: 88.20%\n",
      "Epoch 40/100, Train Loss: 0.3125, Train Accuracy: 88.76%, Test Loss: 0.3371, Test Accuracy: 88.20%\n",
      "Epoch 41/100, Train Loss: 0.3257, Train Accuracy: 88.84%, Test Loss: 0.3354, Test Accuracy: 88.52%\n",
      "Epoch 42/100, Train Loss: 0.3192, Train Accuracy: 88.68%, Test Loss: 0.3366, Test Accuracy: 88.20%\n",
      "Epoch 43/100, Train Loss: 0.3157, Train Accuracy: 88.35%, Test Loss: 0.3373, Test Accuracy: 88.20%\n",
      "Epoch 44/100, Train Loss: 0.3332, Train Accuracy: 88.68%, Test Loss: 0.3364, Test Accuracy: 88.20%\n",
      "Epoch 45/100, Train Loss: 0.3141, Train Accuracy: 88.68%, Test Loss: 0.3386, Test Accuracy: 88.20%\n",
      "Epoch 46/100, Train Loss: 0.3092, Train Accuracy: 88.76%, Test Loss: 0.3381, Test Accuracy: 87.87%\n",
      "Epoch 47/100, Train Loss: 0.3163, Train Accuracy: 88.68%, Test Loss: 0.3388, Test Accuracy: 87.87%\n",
      "Epoch 48/100, Train Loss: 0.3096, Train Accuracy: 88.93%, Test Loss: 0.3428, Test Accuracy: 88.20%\n",
      "Epoch 49/100, Train Loss: 0.3133, Train Accuracy: 88.60%, Test Loss: 0.3433, Test Accuracy: 88.52%\n",
      "Epoch 50/100, Train Loss: 0.3201, Train Accuracy: 88.68%, Test Loss: 0.3409, Test Accuracy: 87.87%\n",
      "Epoch 51/100, Train Loss: 0.3083, Train Accuracy: 88.84%, Test Loss: 0.3405, Test Accuracy: 87.87%\n",
      "Epoch 52/100, Train Loss: 0.3062, Train Accuracy: 88.84%, Test Loss: 0.3398, Test Accuracy: 87.87%\n",
      "Epoch 53/100, Train Loss: 0.3270, Train Accuracy: 88.60%, Test Loss: 0.3410, Test Accuracy: 87.87%\n",
      "Epoch 54/100, Train Loss: 0.3071, Train Accuracy: 88.52%, Test Loss: 0.3394, Test Accuracy: 87.87%\n",
      "Epoch 55/100, Train Loss: 0.3074, Train Accuracy: 88.68%, Test Loss: 0.3418, Test Accuracy: 87.87%\n",
      "Epoch 56/100, Train Loss: 0.3058, Train Accuracy: 88.76%, Test Loss: 0.3449, Test Accuracy: 87.87%\n",
      "Epoch 57/100, Train Loss: 0.3056, Train Accuracy: 88.60%, Test Loss: 0.3424, Test Accuracy: 87.87%\n",
      "Epoch 58/100, Train Loss: 0.3073, Train Accuracy: 88.76%, Test Loss: 0.3439, Test Accuracy: 87.87%\n",
      "Epoch 59/100, Train Loss: 0.3035, Train Accuracy: 88.68%, Test Loss: 0.3481, Test Accuracy: 87.87%\n",
      "Epoch 60/100, Train Loss: 0.3035, Train Accuracy: 88.76%, Test Loss: 0.3440, Test Accuracy: 87.87%\n",
      "Epoch 61/100, Train Loss: 0.3072, Train Accuracy: 88.76%, Test Loss: 0.3454, Test Accuracy: 87.87%\n",
      "Epoch 62/100, Train Loss: 0.3032, Train Accuracy: 88.68%, Test Loss: 0.3467, Test Accuracy: 87.87%\n",
      "Epoch 63/100, Train Loss: 0.3078, Train Accuracy: 88.76%, Test Loss: 0.3454, Test Accuracy: 87.87%\n",
      "Epoch 64/100, Train Loss: 0.3048, Train Accuracy: 88.84%, Test Loss: 0.3460, Test Accuracy: 87.87%\n",
      "Epoch 65/100, Train Loss: 0.3030, Train Accuracy: 88.84%, Test Loss: 0.3457, Test Accuracy: 87.87%\n",
      "Epoch 66/100, Train Loss: 0.3011, Train Accuracy: 88.84%, Test Loss: 0.3485, Test Accuracy: 87.87%\n",
      "Epoch 67/100, Train Loss: 0.2986, Train Accuracy: 88.68%, Test Loss: 0.3502, Test Accuracy: 87.87%\n",
      "Epoch 68/100, Train Loss: 0.2985, Train Accuracy: 88.76%, Test Loss: 0.3484, Test Accuracy: 87.87%\n",
      "Epoch 69/100, Train Loss: 0.2984, Train Accuracy: 89.01%, Test Loss: 0.3477, Test Accuracy: 88.20%\n",
      "Epoch 70/100, Train Loss: 0.3102, Train Accuracy: 88.84%, Test Loss: 0.3483, Test Accuracy: 88.20%\n",
      "Epoch 71/100, Train Loss: 0.3007, Train Accuracy: 88.76%, Test Loss: 0.3537, Test Accuracy: 87.54%\n",
      "Epoch 72/100, Train Loss: 0.3175, Train Accuracy: 88.84%, Test Loss: 0.3549, Test Accuracy: 86.23%\n",
      "Epoch 73/100, Train Loss: 0.3161, Train Accuracy: 89.09%, Test Loss: 0.3584, Test Accuracy: 87.87%\n",
      "Epoch 74/100, Train Loss: 0.3037, Train Accuracy: 88.84%, Test Loss: 0.3545, Test Accuracy: 88.52%\n",
      "Epoch 75/100, Train Loss: 0.3108, Train Accuracy: 88.93%, Test Loss: 0.3528, Test Accuracy: 86.89%\n",
      "Epoch 76/100, Train Loss: 0.2971, Train Accuracy: 88.93%, Test Loss: 0.3539, Test Accuracy: 87.87%\n",
      "Epoch 77/100, Train Loss: 0.2979, Train Accuracy: 89.09%, Test Loss: 0.3548, Test Accuracy: 87.87%\n",
      "Epoch 78/100, Train Loss: 0.2955, Train Accuracy: 88.84%, Test Loss: 0.3545, Test Accuracy: 87.54%\n",
      "Epoch 79/100, Train Loss: 0.2947, Train Accuracy: 89.01%, Test Loss: 0.3566, Test Accuracy: 87.87%\n",
      "Epoch 80/100, Train Loss: 0.2961, Train Accuracy: 89.17%, Test Loss: 0.3543, Test Accuracy: 87.87%\n",
      "Epoch 81/100, Train Loss: 0.2929, Train Accuracy: 88.76%, Test Loss: 0.3558, Test Accuracy: 87.21%\n",
      "Epoch 82/100, Train Loss: 0.3108, Train Accuracy: 89.09%, Test Loss: 0.3594, Test Accuracy: 88.20%\n",
      "Epoch 83/100, Train Loss: 0.3053, Train Accuracy: 88.60%, Test Loss: 0.3581, Test Accuracy: 87.54%\n",
      "Epoch 84/100, Train Loss: 0.3200, Train Accuracy: 89.01%, Test Loss: 0.3573, Test Accuracy: 87.21%\n",
      "Epoch 85/100, Train Loss: 0.2943, Train Accuracy: 89.25%, Test Loss: 0.3614, Test Accuracy: 87.87%\n",
      "Epoch 86/100, Train Loss: 0.2931, Train Accuracy: 88.76%, Test Loss: 0.3605, Test Accuracy: 86.23%\n",
      "Epoch 87/100, Train Loss: 0.2977, Train Accuracy: 88.84%, Test Loss: 0.3611, Test Accuracy: 86.23%\n",
      "Epoch 88/100, Train Loss: 0.3182, Train Accuracy: 89.17%, Test Loss: 0.3592, Test Accuracy: 86.89%\n",
      "Epoch 89/100, Train Loss: 0.3078, Train Accuracy: 89.01%, Test Loss: 0.3587, Test Accuracy: 87.54%\n",
      "Epoch 90/100, Train Loss: 0.2919, Train Accuracy: 88.76%, Test Loss: 0.3622, Test Accuracy: 87.54%\n",
      "Epoch 91/100, Train Loss: 0.2907, Train Accuracy: 88.84%, Test Loss: 0.3586, Test Accuracy: 86.56%\n",
      "Epoch 92/100, Train Loss: 0.2897, Train Accuracy: 88.84%, Test Loss: 0.3648, Test Accuracy: 87.21%\n",
      "Epoch 93/100, Train Loss: 0.2907, Train Accuracy: 89.09%, Test Loss: 0.3640, Test Accuracy: 87.54%\n",
      "Epoch 94/100, Train Loss: 0.2917, Train Accuracy: 89.34%, Test Loss: 0.3668, Test Accuracy: 87.21%\n",
      "Epoch 95/100, Train Loss: 0.2898, Train Accuracy: 89.17%, Test Loss: 0.3627, Test Accuracy: 86.89%\n",
      "Epoch 96/100, Train Loss: 0.3144, Train Accuracy: 89.17%, Test Loss: 0.3689, Test Accuracy: 86.89%\n",
      "Epoch 97/100, Train Loss: 0.2902, Train Accuracy: 89.17%, Test Loss: 0.3632, Test Accuracy: 87.87%\n",
      "Epoch 98/100, Train Loss: 0.2893, Train Accuracy: 88.93%, Test Loss: 0.3686, Test Accuracy: 87.21%\n",
      "Epoch 99/100, Train Loss: 0.2922, Train Accuracy: 89.01%, Test Loss: 0.3672, Test Accuracy: 85.25%\n",
      "Epoch 100/100, Train Loss: 0.2907, Train Accuracy: 88.84%, Test Loss: 0.3667, Test Accuracy: 86.89%\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ClimateDataset(X_train, y_train)\n",
    "test_dataset = ClimateDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SnowForecastNN(input_size=X_train.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        labels = labels.view(-1, 1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    \n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            labels = labels.view(-1, 1)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Snow       0.88      0.98      0.93       270\n",
      "        Snow       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.87       305\n",
      "   macro avg       0.44      0.49      0.46       305\n",
      "weighted avg       0.78      0.87      0.82       305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_predictions, target_names=['No Snow', 'Snow']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Although 87% test accuracy is achieved but the model is predicting mostly the majority class. In such cases techniques like stratifies group k-fold cross-validation and weighting random sampling can be used to mitigate the class imabalce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usama",
   "language": "python",
   "name": "usama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
